\section{Two Tower Neural Networks} \label{nn}

Above the input layer is the embedding layer; it is a fully
connected layer that projects the sparse representation to
a dense vector.  \cite{10.1145/3038912.3052569} \cite{DBLP:journals/corr/abs-1708-05027}    

$\begin{bmatrix}
1 & 2 & 3\\
a & b & c
\end{bmatrix} $ is a matrix

\subsection{Cold Start}\label{cold-start}

\begin{comment}
\noindent\rule{2cm}{0.4pt}

aTwo tower neural network architecture 
User embedding
Post embedding
embedding = vector
normalize vector
dot product of post and user vector
pre trained embeddings

\noindent\rule{2cm}{0.4pt}
\end{comment}

\section{Convolutional Neural Networks}

Unfortunately, most large corporations are closed-source, keeping competition on the internet. With a few exceptions, with the the recent change of X (Twitter) going open-source. \ref{cnn/xalgorithm} The next following subsections will explain some of the popular open-source image recognition neural networks.

\begin{comment}
\input{CNN/alexnet}
\input{CNN/vggnet}
\input{CNN/resnet}
\input{CNN/googlenet}
\input{CNN/efficientnet}
\input{CNN/siamesenetwork}
\input{CNN/xalgorithm}

\end{comment}