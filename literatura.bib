@INPROCEEDINGS{10142790,
  author={Akshya, J and Mehra, Vinit and Sundarrajan, M. and Sri, Pattapu Teja and Choudhry, Mani Deepak},
  booktitle={2023 7th International Conference on Intelligent Computing and Control Systems (ICICCS)}, 
  title={Efficient Net-based Expert System for Personalized Facial Skincare Recommendations}, 
  year={2023},
  volume={},
  number={},
  pages={1151-1156},
  keywords={Training;Filtering;Social networking (online);Biological system modeling;Transfer learning;Collaboration;Skin;Deep Learning;Recommendation System;Skin Tone;Skin Type;Acne;Transfer Learning;EfficientNet},
  doi={10.1109/ICICCS56967.2023.10142790}}


@misc{ig-explore,
	author = {Ivan Medvedev, Haotian Wu, Taylor Gordon},
	title = "Powered by AI: Instagram’s Explore recommender system",
	howpublished = "\url{https://ai.meta.com/blog/powered-by-ai-instagrams-explore-recommender-system/}",
    year = {2019},
    note = {[Cited 30/9/2024]}
}

@misc{ig-new-content,
  author = {Amogh Mahapatra},
  title = {How Instagram Suggests New Content},
  howpublished = {\url{https://engineering.fb.com/2020/12/10/web/how-instagram-suggests-new-content/}},
  year = {2020},
  note = {[Cited 30/9/2024]}
}

@ARTICLE{10373857,
  author={Lee, Won-Min and Cho, Yoon-Sik},
  journal={IEEE Access}, 
  title={A Flexible Two-Tower Model for Item Cold-Start Recommendation}, 
  year={2023},
  volume={11},
  number={},
  pages={146194-146207},
  keywords={Adaptation models;Training;Poles and towers;Color;Sensitivity;Recommender systems;Motion pictures;Neural networks;Recommendation system;cold-start problem;hybrid neural network},
  doi={10.1109/ACCESS.2023.3346918}}

@inproceedings{10.1145/3038912.3052569,
author = {He, Xiangnan and Liao, Lizi and Zhang, Hanwang and Nie, Liqiang and Hu, Xia and Chua, Tat-Seng},
title = {Neural Collaborative Filtering},
year = {2017},
isbn = {9781450349130},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3038912.3052569},
doi = {10.1145/3038912.3052569},
abstract = {In recent years, deep neural networks have yielded immense success on speech recognition, computer vision and natural language processing. However, the exploration of deep neural networks on recommender systems has received relatively less scrutiny. In this work, we strive to develop techniques based on neural networks to tackle the key problem in recommendation --- collaborative filtering --- on the basis of implicit feedback.Although some recent work has employed deep learning for recommendation, they primarily used it to model auxiliary information, such as textual descriptions of items and acoustic features of musics. When it comes to model the key factor in collaborative filtering --- the interaction between user and item features, they still resorted to matrix factorization and applied an inner product on the latent features of users and items.By replacing the inner product with a neural architecture that can learn an arbitrary function from data, we present a general framework named NCF, short for Neural network-based Collaborative Filtering. NCF is generic and can express and generalize matrix factorization under its framework. To supercharge NCF modelling with non-linearities, we propose to leverage a multi-layer perceptron to learn the user-item interaction function. Extensive experiments on two real-world datasets show significant improvements of our proposed NCF framework over the state-of-the-art methods. Empirical evidence shows that using deeper layers of neural networks offers better recommendation performance.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web},
pages = {173–182},
numpages = {10},
keywords = {collaborative filtering, deep learning, implicit feedback, matrix factorization, neural networks},
location = {Perth, Australia},
series = {WWW '17}
}

@article{DBLP:journals/corr/abs-1708-05027,
  author       = {Xiangnan He and
                  Tat{-}Seng Chua},
  title        = {Neural Factorization Machines for Sparse Predictive Analytics},
  journal      = {CoRR},
  volume       = {abs/1708.05027},
  year         = {2017},
  url          = {http://arxiv.org/abs/1708.05027},
  eprinttype    = {arXiv},
  eprint       = {1708.05027},
  timestamp    = {Mon, 13 Aug 2018 16:47:16 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1708-05027.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@INPROCEEDINGS{10408929,
  author={Ye, Qing and Cai, Xiaodong and Xue, Yun and Zhang, Yanyan},
  booktitle={2023 IEEE 11th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={An encoder enhanced sequence recommendation algorithm}, 
  year={2023},
  volume={11},
  number={},
  pages={1346-1351},
  keywords={Training;Measurement;Predictive models;Feature extraction;Prediction algorithms;Data models;Vectors;Time factors;Recommender systems;Sports;sequence recommendation;self-supervised learning;comparative learning;recommender systems},
  doi={10.1109/ITAIC58329.2023.10408929}}

@article{esvdascfacsasdicars,
author = {Rodpysh, Keyvan and Mirabedini, Seyed and Banirostam, Touraj},
year = {2021},
month = {05},
pages = {},
title = {Employing singular value decomposition and similarity criteria for alleviating cold start and sparse data in context-aware recommender systems},
volume = {23},
journal = {Electronic Commerce Research},
doi = {10.1007/s10660-021-09488-7}
}

@article{GAO2020409,
title = {A novel method to compute the weights of neural networks},
journal = {Neurocomputing},
volume = {407},
pages = {409-427},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.03.114},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220307050},
author = {Zhentao Gao and Yuanyuan Chen and Zhang Yi},
keywords = {Neural networks, Gradient free, Closed-form solution, White box models},
abstract = {Neural networks are the main strength of modern artificial intelligence; they have demonstrated revolutionary performance in a wide range of applications. In practice, the weights of neural networks are generally obtained indirectly using iterative training methods. Such methods are inefficient and problematic in many respects. Besides, neural networks trained end-to-end by such methods are typical black box models that are hard to interpret. Thus, it would be significantly better if the weights of a neural network could be calculated directly. In this paper, we located the key for calculating the weights of a neural network directly: assigning proper targets to the hidden units. Furthermore, if such targets are assigned, the neural network becomes a white box model that is easy to interpret. Thus, we propose a framework for solving the weights of a neural network and provide a sample implementation of the framework. The implementation was tested in various classification and regression experiments. Compared with neural networks trained using traditional methods, the constructed ones using solved weights had similar or better performance on many tasks, while remaining interpretable. Given the early stage of the proposed approach, many improvements are expectable in future developments.}
}

@INPROCEEDINGS{9784987,
  author={Chowdhury, Ayanesh and Chahar, Ankit and Eswara, Rohan and Raheem, Mohammed Abdul and Ehetesham, Shaik and Thulasidoss, Bharath Kumar},
  booktitle={2022 8th International Conference on Advanced Computing and Communication Systems (ICACCS)}, 
  title={Fetal Health Prediction using neural networks}, 
  year={2022},
  volume={1},
  number={},
  pages={256-260},
  keywords={Pregnancy;Industries;Pediatrics;Technological innovation;Medical services;Predictive models;Fetus;Fetal health prediction;convolution neural network;Deep Learning;artificial neural network;comparative analysis},
  doi={10.1109/ICACCS54159.2022.9784987}}

@INPROCEEDINGS{8609672,
  author={Mittal, Namita and Sharma, Divya and Joshi, Manju Lata},
  booktitle={2018 IEEE/WIC/ACM International Conference on Web Intelligence (WI)}, 
  title={Image Sentiment Analysis Using Deep Learning}, 
  year={2018},
  volume={},
  number={},
  pages={684-687},
  keywords={Sentiment analysis;Deep learning;Biological neural networks;Feature extraction;Visualization;Analytical models;image sentiment analysis, deep learning, deep neural network, convolutional neural network, Region based CNN and Fast R-CNN.},
  doi={10.1109/WI.2018.00-11}}

